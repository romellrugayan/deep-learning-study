{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit Recognizer Using Convolutional Neural Network (CNN)\n",
    "\n",
    "The data files train.csv and test.csv contain gray-scale images of hand-drawn digits, from zero through nine.\n",
    "\n",
    "Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255, inclusive.\n",
    "\n",
    "The training data set, (train.csv), has 785 columns. The first column, called \"label\", is the digit that was drawn by the user. The rest of the columns contain the pixel-values of the associated image.\n",
    "\n",
    "Each pixel column in the training set has a name like pixelx, where x is an integer between 0 and 783, inclusive. To locate this pixel on the image, suppose that we have decomposed x as x = i * 28 + j, where i and j are integers between 0 and 27, inclusive. Then pixelx is located on row i and column j of a 28 x 28 matrix, (indexing by zero). by: kaggle.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# importing python libraries\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.iloc[:, 1:].values\n",
    "y = train.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert label into a one-hot vector [m,] --> [m,10]\n",
    "# where 10 is no. of columns for 0's and 1's (equivalent to digits 0 to 9)\n",
    "from keras.utils import to_categorical\n",
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape the array to extract image size: 28 x 28\n",
    "m = X.shape[0]\n",
    "X_new = np.zeros((m, 28, 28), dtype=float)\n",
    "for i in range(m):\n",
    "    digit = X[i].reshape(28, 28)\n",
    "    X_new[i] = digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# view the image\n",
    "single_image = X[6].reshape(28,28)\n",
    "plt.imshow(single_image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape the array for tensorflow\n",
    "X_new = np.reshape(X_new, [-1, 28, 28, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the values to a range 0 to 1\n",
    "X_new = X_new/ 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_new, y, test_size = 0.10, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters for convolutional network\n",
    "num_labels = 10\n",
    "input_shape = (28, 28, 1)\n",
    "batch_size = 128\n",
    "kernel_size = 3\n",
    "pool_size = 2\n",
    "filters = 64\n",
    "dropout = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the neural network requires configuring the layers of the model, then compiling the model.\n",
    "# import tensorflow and keras libraries\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, activation='relu', input_shape=input_shape),\n",
    "    keras.layers.MaxPooling2D(pool_size),\n",
    "    keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size),\n",
    "    keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, activation='relu'),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dropout(dropout),\n",
    "    keras.layers.Dense(num_labels, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37800 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 30s 781us/sample - loss: 0.3546 - accuracy: 0.8909\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 33s 879us/sample - loss: 0.0834 - accuracy: 0.9736\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 33s 878us/sample - loss: 0.0595 - accuracy: 0.9814\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 34s 890us/sample - loss: 0.0445 - accuracy: 0.9859\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 33s 886us/sample - loss: 0.0390 - accuracy: 0.9877\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 33s 875us/sample - loss: 0.0331 - accuracy: 0.9896\n",
      "Epoch 7/10\n",
      "37800/37800 [==============================] - 35s 921us/sample - loss: 0.0279 - accuracy: 0.9908\n",
      "Epoch 8/10\n",
      "37800/37800 [==============================] - 33s 867us/sample - loss: 0.0260 - accuracy: 0.9917\n",
      "Epoch 9/10\n",
      "37800/37800 [==============================] - 33s 882us/sample - loss: 0.0229 - accuracy: 0.9929\n",
      "Epoch 10/10\n",
      "37800/37800 [==============================] - 33s 875us/sample - loss: 0.0194 - accuracy: 0.9940\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21c458d6198>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/1 - 1s - loss: 0.1413 - accuracy: 0.9893\n",
      "\n",
      "Test accuracy: 0.9892857\n"
     ]
    }
   ],
   "source": [
    "# evaluate accuracy\n",
    "test_loss, test_acc = model.evaluate(X_val,  y_val, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below lines are for kaggle knowledge competition:\n",
    "This is to generate the submission csv file based on the given test data without the true/target label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test dataset\n",
    "test_data = test.iloc[:, :].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape the array for tensorflow\n",
    "m = test_data.shape[0]\n",
    "X_test = np.zeros((m, 28, 28), dtype=float)\n",
    "for i in range(m):\n",
    "    digit = test_data[i].reshape(28, 28)\n",
    "    X_test[i] = digit\n",
    "X_test = np.reshape(X_test, [-1, 28, 28, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the values to a range 0 to 1\n",
    "X_test = X_test/ 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_array = np.zeros((28000,1))\n",
    "for i in range(28000):\n",
    "    predictions_array[i] = np.argmax(predictions[i])\n",
    "\n",
    "predictions_array = predictions_array.astype(int).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sample submission template\n",
    "template = pd.read_csv('data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your submission was successfully saved!\n"
     ]
    }
   ],
   "source": [
    "data = {'ImageId': template.ImageId, 'Label': predictions_array}\n",
    "output = pd.DataFrame(data)\n",
    "output.to_csv('my_submission.csv', index=False)\n",
    "print(\"Your submission was successfully saved!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
