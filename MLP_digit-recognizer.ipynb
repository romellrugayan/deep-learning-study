{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit Recognizer Using Multi-Layer Perceptron (MLP)\n",
    "\n",
    "The data files train.csv and test.csv contain gray-scale images of hand-drawn digits, from zero through nine.\n",
    "\n",
    "Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255, inclusive.\n",
    "\n",
    "The training data set, (train.csv), has 785 columns. The first column, called \"label\", is the digit that was drawn by the user. The rest of the columns contain the pixel-values of the associated image.\n",
    "\n",
    "Each pixel column in the training set has a name like pixelx, where x is an integer between 0 and 783, inclusive. To locate this pixel on the image, suppose that we have decomposed x as x = i * 28 + j, where i and j are integers between 0 and 27, inclusive. Then pixelx is located on row i and column j of a 28 x 28 matrix, (indexing by zero). - by kaggle.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# importing python libraries\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.iloc[:, 1:].values\n",
    "y = train.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# view the image\n",
    "single_image = X[6].reshape(28,28)\n",
    "plt.imshow(single_image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the values to a range 0 to 1\n",
    "X = X.astype('float32') / 255.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.10, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# importing TensorFlow and tf.keras libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the neural network (MLP) requires configuring the layers of the model, then compiling the model.\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(256, kernel_initializer='uniform', activation='relu'),\n",
    "    keras.layers.Dropout(0.45),\n",
    "    keras.layers.Dense(256, kernel_initializer='uniform', activation='relu'),\n",
    "    keras.layers.Dropout(0.45),\n",
    "    keras.layers.Dense(256, kernel_initializer='uniform', activation='relu'),\n",
    "    keras.layers.Dropout(0.45),\n",
    "    keras.layers.Dense(10, kernel_initializer='uniform', activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37800 samples\n",
      "Epoch 1/20\n",
      "37800/37800 [==============================] - 2s 46us/sample - loss: 0.6103 - accuracy: 0.8019\n",
      "Epoch 2/20\n",
      "37800/37800 [==============================] - 1s 34us/sample - loss: 0.2370 - accuracy: 0.9296\n",
      "Epoch 3/20\n",
      "37800/37800 [==============================] - 1s 34us/sample - loss: 0.1836 - accuracy: 0.9451\n",
      "Epoch 4/20\n",
      "37800/37800 [==============================] - 1s 34us/sample - loss: 0.1567 - accuracy: 0.9527\n",
      "Epoch 5/20\n",
      "37800/37800 [==============================] - 1s 34us/sample - loss: 0.1342 - accuracy: 0.9598\n",
      "Epoch 6/20\n",
      "37800/37800 [==============================] - 1s 34us/sample - loss: 0.1237 - accuracy: 0.9620\n",
      "Epoch 7/20\n",
      "37800/37800 [==============================] - 1s 34us/sample - loss: 0.1089 - accuracy: 0.9674\n",
      "Epoch 8/20\n",
      "37800/37800 [==============================] - 1s 35us/sample - loss: 0.1036 - accuracy: 0.9689\n",
      "Epoch 9/20\n",
      "37800/37800 [==============================] - 1s 36us/sample - loss: 0.1003 - accuracy: 0.9693\n",
      "Epoch 10/20\n",
      "37800/37800 [==============================] - 2s 57us/sample - loss: 0.0909 - accuracy: 0.9725\n",
      "Epoch 11/20\n",
      "37800/37800 [==============================] - 2s 56us/sample - loss: 0.0864 - accuracy: 0.9731\n",
      "Epoch 12/20\n",
      "37800/37800 [==============================] - 2s 54us/sample - loss: 0.0834 - accuracy: 0.9751\n",
      "Epoch 13/20\n",
      "37800/37800 [==============================] - 2s 55us/sample - loss: 0.0749 - accuracy: 0.9767\n",
      "Epoch 14/20\n",
      "37800/37800 [==============================] - 2s 56us/sample - loss: 0.0736 - accuracy: 0.9772\n",
      "Epoch 15/20\n",
      "37800/37800 [==============================] - 2s 54us/sample - loss: 0.0745 - accuracy: 0.9771\n",
      "Epoch 16/20\n",
      "37800/37800 [==============================] - 2s 53us/sample - loss: 0.0690 - accuracy: 0.9790\n",
      "Epoch 17/20\n",
      "37800/37800 [==============================] - 2s 53us/sample - loss: 0.0670 - accuracy: 0.9798\n",
      "Epoch 18/20\n",
      "37800/37800 [==============================] - 2s 56us/sample - loss: 0.0647 - accuracy: 0.9802\n",
      "Epoch 19/20\n",
      "37800/37800 [==============================] - 2s 56us/sample - loss: 0.0616 - accuracy: 0.9805\n",
      "Epoch 20/20\n",
      "37800/37800 [==============================] - 2s 54us/sample - loss: 0.0609 - accuracy: 0.9824\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25984f11240>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "model.fit(X_train, y_train, batch_size=128, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/1 - 0s - loss: 0.2975 - accuracy: 0.9748\n",
      "\n",
      "Test accuracy: 0.9747619\n"
     ]
    }
   ],
   "source": [
    "# evaluate accuracy\n",
    "test_loss, test_acc = model.evaluate(X_val,  y_val, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below lines are for kaggle competition submission\n",
    "This is to generate the submission csv file based on the given test data without the true/target label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test dataset\n",
    "X_test = test.iloc[:, :].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the values to a range 0 to 1\n",
    "X_test = X_test.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_array = np.zeros((28000,1))\n",
    "for i in range(28000):\n",
    "    predictions_array[i] = np.argmax(predictions[i])\n",
    "\n",
    "predictions_array = predictions_array.astype(int).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sample submission template\n",
    "template = pd.read_csv('/kaggle/input/digit-recognizer/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your submission was successfully saved!\n"
     ]
    }
   ],
   "source": [
    "data = {'ImageId': template.ImageId, 'Label': predictions_array}\n",
    "output = pd.DataFrame(data)\n",
    "output.to_csv('my_submission.csv', index=False)\n",
    "print(\"Your submission was successfully saved!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
